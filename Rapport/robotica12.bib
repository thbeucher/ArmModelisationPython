
@inproceedings{todorov05_ACC,
  author = {Todorov, E. and Li, W.},
  title = {A generalized iterative {LQG} method for locally-optimal feedback control of constrained nonlinear stochastic systems},
  booktitle = {Proceedings of the American Control Conference},
pages = {300-306},
  year = {2005}
}

@article{Sutton2000,
author = {Sutton, Richard S and Mcallester, David and Singh, Satinder and Mansour, Yishay},
journal = {Processing},
keywords = {policy gradient,policy search},
mendeley-tags = {policy gradient,policy search},
pages = {1057--1063},
title = {{Policy Gradient Methods for Reinforcement Learning with Function Approximation}},
year = {2000}
}

@inproceedings{todorov03_NIPS,
title        = {A Minimal Intervention Principle for Coordinated Movement},
author       = {Todorov, E. and Jordan, M.~I.},
booktitle    = {NIPS},
pages        = {27-34},
year         = {2003}
}

@inproceedings{drucker97,
  author = {Drucker, Harris and Kaufman, Chris and Burges L. and Smola, Alex and Vapnik, Vladimir},
  booktitle = {Advances in Neural Information Processing Systems 9},
  pages = {155--161},
  title = {Support vector regression machines},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.5909},
  volume = 9,
  year = 1997,
  keywords = {regression svms},
}

@incollection{rahimi08,
 title = {Random Features for Large-Scale Kernel Machines},
 author = {Ali Rahimi and Benjamin Recht},
 booktitle = {Advances in Neural Information Processing Systems 20},
 editor = {J.C. Platt and D. Koller and Y. Singer and S. Roweis},
 publisher = {MIT Press},
 address = {Cambridge, MA},
 pages = {1177--1184},
 year = {2008}
}


@book{bjorck96,
   author = "{\AA}. Bj{\"o}rck",
   year = "1996",
   title = " Numerical Methods for Least Squares Problems",
   publisher = "SIAM",
   address = "Philadelphia",
   kwds = "survey, sparse, iter"
}

@book{sayed08,
 author = {Sayed, Ali H.},
 title = {Adaptive Filters},
 year = {2008},
 isbn = {0470253886},
 publisher = {Wiley-IEEE Press},
} 

@inproceedings{gijsbert11,
  author    = {Arjan Gijsberts and
               Giorgio Metta},
  title     = {Incremental learning of robot dynamics using random features},
  booktitle = {ICRA},
  year      = {2011},
  pages     = {951-956},
  ee        = {http://dx.doi.org/10.1109/ICRA.2011.5980191},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{theodorou10,
  title={Reinforcement learning of motor skills in high dimensions: a path integral approach},
  author={Theodorou, E. and Buchli, J. and Schaal, S.},
  booktitle={International Conference on Robotics and Automation},
  pages={2397--2403},
  year={2010},
  organization={IEEE}
}
@inproceedings{ivaldi10_IROS,
  title={Approximate optimal control for reaching and trajectory planning in a humanoid robot},
  author={Ivaldi, S. and Fumagalli, M. and Nori, F. and Baglietto, M. and Metta, G. and Sandini, G.},
  booktitle={Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on},
  pages={1290--1296},
  year={2010},
  organization={IEEE}
}

@inproceedings{stulp11_humanoids,
  title={Hierarchical reinforcement learning with movement primitives},
  author={Stulp, F. and Schaal, S.},
  booktitle={IEEE-RAS International Conference on Humanoid Robots},
  pages={231--238},
  year={2011},
  organization={IEEE}
}

@article{buchli11_IJRR,
  title={Learning variable impedance control},
  author={Buchli, J. and Stulp, F. and Theodorou, E. and Schaal, S.},
  journal={The International Journal of Robotics Research},
  volume={30},
  number={7},
  pages={820},
  year={2011},
  publisher={SAGE Publications}
}

@book{bertsekas95,
  author =	 {Bertsekas, D.~P.},
  title =	 {Dynamic {P}rogramming and {O}ptimal {C}ontrol},
  year =	 {1995},
  publisher =	 {Athena Scientific},
  address =	 {Belmont, MA}
}

@InProceedings{butz2008,
  Author         = {M. V. Butz and O. Herbort},
  Title          = {Context-dependent predictions and cognitive arm
                   control with {XCSF}},
  BookTitle      = {Proceedings of the 10th annual conference on Genetic
                   and evolutionary computation},
  Pages          = {1357-1364},
  Publisher      = {{ACM} New York, {NY,} {USA}},
  year           = 2008
}

@techreport{wilson06,
  Author         = {Wilson, S.~W.},
  Title          = {Three Architectures for Continuous Action},
  institution    = {No. 2006019, Illinois Genetic Algorithms Laboratory, University of Illinois at Urbana-Champaign},
  year           = 2006
}

@InProceedings{tran07,
  Author         = {Tran, T.~H. and Sanza, C. and Duthen, Y. and Nguyen, D.~T.},
  Title          = {{XCSF} with Computed Continuous Action},
  BookTitle      = {Proceedings of the 9th annual Conference on Genetic
                   and Evolutionary Computation (GECCO'07)},
  Pages          = {1861-1869},
  Publisher      = {{ACM} New York, {NY,} {USA}},
  year           = 2007
}

@Article{	  wilson1995,
  author	= {Wilson, S.~W.},
  title		= {{C}lassifier {F}itness {B}ased on {A}ccuracy},
  journal	= {Evolutionary Computation},
  volume	= {3},
  number	= {2},
  pages		= {149--175},
  keywords	= {LCS, XCS, Classifier systems, strength, fitness, accuracy,
		  mapping, generalization, restricted mating, niche genetic
		  algorithm},
  abstract	= {In many classifier systems, the classifier strength
		  parameter serves as a predictor of future payoff and as the
		  classifier's fitness for the genetic algorithm. We
		  investigate a classifier system, XCS, in which each
		  classifier maintains a prediction of expected payoff, but
		  the classifier's fitness is given by a measure of the
		  prediction's accuracy. The system executes the genetic
		  algorithm in niches defined by the match sets, instead of
		  panmictically. These aspects of XCS result in its
		  population tending to form a complete and accurate mapping
		  X x A -> P from inputs and actions to payoff predictions.
		  Further, XCS tends to evolve classifiers that are maximally
		  general, subject to an accuracy criterion. Besides
		  introducing a new direction for classifier system research,
		  these properties of XCS make it suitable for a wide range
		  of reinforcement learning situations where generalization
		  over states is desirable.},
  year		= 1995
}

@InProceedings{	  wilson2001,
  title		= {Function Approximation with a Classifier System},
  author	= {Wilson, S.~W.},
  pages		= {974--981},
  year		= 2001,
  publisher	= {Morgan Kaufmann},
  booktitle	= {Proceedings of the Genetic and Evolutionary Computation
		  Conference (GECCO-2001)},
  address	= {San Francisco, California, USA},
  keywords	= {LCS, classifier systems, function approximation, XCS,
		  weight vector, generalized classifier},
  isbn		= {1-55860-774-9}
}

@Article{	  wilson2002,
  author	= {Wilson, S.~W.},
  title		= {{C}lassifiers that {A}pproximate {F}unctions},
  journal	= {Natural Computing},
  volume	= {1},
  pages		= {211-234},
  number	= {2-3},
  year		= 2002
}

@Article{butz2004,
  author	= {Butz, M.~V. and Kovacs, T. and Lanzi, P.~L. and Wilson,
		  S.~W.},
  title		= {Toward a Theory of Generalization and Learning in {XCS}},
  journal	= {IEEE Transactions on Evolutionary Computation},
  volume	= {8},
  number	= {1},
  pages		= {28--46},
  year		= 2004
}

@Article{butz2005,
  title		= {{Computational Complexity of the XCS Classifier System}},
  author	= {Butz, M.~V. and Goldberg, D.~E. and Lanzi, P.-L.},
  journal	= {Foundations of Learning Classifier Systems},
  volume	= {51},
  pages		= {91--125},
  year		= {2005},
  publisher	= {Springer}
}

@InProceedings{bernado01,
  author =	 {Bernad\'o-Mansilla, E. and Llor\`a, X. and Garrel, J.~M.},
  title =	 {{XCS} and {GALE}~: a comparative study of two
                  {L}earning {C}lassifer {S}ystems with six other
                  learning algorithms on classification tasks},
  booktitle =	 {Proceedings of the fourth international workshop on
                  {L}earning {C}lassifer {S}ystems},
  year =	 {2001},
  editor =	 {Lanzi, P.-L. and Stolzmann, W. and Wilson, S.~W.}
}

@article{lanzi02_jsc,
  author =	 {Lanzi, P.-L.},
  title =	 {{L}earning {C}Lassifier {S}ystems from a {R}einforcement {L}earning {P}erspective},
  journal =	 {Journal of Soft Computing},
  volume = {6},
  number =	 {3-4},
  year =	 {2002},
  pages =	 {162-170}
}

%------------------------------------------------------------------------------

% RL

% REINFORCE
@article{Williams92,
author = {Williams, Ronald J.},
doi = {10.1007/BF00992696},
issn = {0885-6125},
journal = {Machine Learning},
number = {3-4},
pages = {229--256},
title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
url = {http://www.springerlink.com/index/10.1007/BF00992696},
volume = {8},
year = {1992}
}

% Cross-Entropy

@article{Hansen2003,
  title={Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation ({CMA-ES}).},
  author={Hansen, N. and Muller, S.D. and Koumoutsakos, P.},
  journal={Evolutionary Computation},
  volume={11},
  number={1},
  pages={1--18},
  year={2003},
  publisher={MIT Press}
}

@article{Rubinstein97,
title = {Optimization of computer simulation models with rare events},
journal = {European Journal of Operational Research},
volume = {99},
number = {1},
pages = {89--112},
year = {1997},
issn = {0377-2217},
doi = {10.1016/S0377-2217(96)00385-2},
url = {http://www.sciencedirect.com/science/article/B6VCT-3SWY0P1-X/2/9268866f182f6800f26b042ca64421f5},
author = {Reuven Y. Rubinstein}
}

@article{Rubinstein99,
author = {Rubinstein, Reuven Y.},
title = {The Cross-Entropy Method for Combinatorial and Continuous Optimization},
doi = {10.3390/entropy-e10020100},
issn = {1387-5841},
journal = {Methodology and Computing in Applied Probability},
keywords = {Continuous Optimization,Cross-Entropy},
mendeley-tags = {Continuous Optimization,Cross-Entropy},
volume = {1},
number = {2},
pages = {127--190},
year = {1999},
}

@article{DeBoer05,
author = {de Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
doi = {10.1007/s10479-005-5724-z},
file = {:home/didier/papiers/de Boer et al. - 2005 - A Tutorial on the Cross-Entropy Method.pdf:pdf},
issn = {0254-5330},
journal = {Annals of Operations Research},
keywords = {CE,cross-entropy method,machine learning,monte-carlo simulation,randomized optimization},
mendeley-tags = {CE},
number = {1},
pages = {19--67},
title = {{A Tutorial on the Cross-Entropy Method}},
url = {http://www.springerlink.com/index/10.1007/s10479-005-5724-z},
volume = {134},
year = {2005}
}

@inproceedings{HeidrichMeisner2008,
author = {Heidrich-Meisner, V. and Igel, Christian},
booktitle = {Proceedings of the 16th ESANN},
keywords = {CMA-ES,Evolution Strategies,policy gradient},
title = {{Similarities and differences between policy gradient methods and evolution strategies}},
year = {2008}
}

@article{Szita06,
author = {Szita, Istv\'{a}n and L\"{o}rincz, Andr\'{a}s},
doi = {10.1162/neco.2006.18.12.2936},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Computer Simulation,Entropy,Humans,Learning,Models, Statistical,Reinforcement (Psychology)},
number = {12},
pages = {2936--41},
pmid = {17052153},
title = {{Learning Tetris using the noisy cross-entropy method.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17052153},
volume = {18},
year = {2006}
}

@phdthesis{Thiery2010,
author = {Thi\'{e}ry, Christophe},
school = {Universit\'{e} Henri Poincar\'{e} - Nancy 1},
title = {{It\'{e}ration sur les Politiques Optimiste et Apprentissage du Jeu de Tetris}},
url = {http://tel.archives-ouvertes.fr/tel-00550081/},
year = {2010}
}

% Autres 

@inproceedings{Kormushev2010,
author = {Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
booktitle = {Proc. IROS},
title = {{Robot Motor Skill Coordination with EM-based Reinforcement Learning}},
year = {2010}
}

@article{Peters2008b,
author = {Peters, Jan and Schaal, Stefan},
file = {:home/didier/papiers/Peters, Schaal - 2007 - Natural actor-critic.pdf:pdf},
journal = {Neurocomputing},
keywords = {NAC,actor-critic methods,compatible function approximation,eNAC,natural gradients,policy gradient methods,reinforcement learning,robot},
mendeley-tags = {NAC,eNAC},
volume = {Nov.},
title = {{Natural actor-critic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231208000532},
year = {2007}
}

@article{Peters2008NN,
author = {Peters, Jan and Schaal, Stefan},
doi = {10.1016/j.neunet.2008.02.003},
file = {:home/didier/papiers/peters-NN2008.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
number = {4},
pages = {682--97},
pmid = {18482830},
title = {{Reinforcement learning of motor skills with policy gradients.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18482830},
volume = {21},
year = {2008}
}

@article{Kober2008,
author = {Kober, Jens and Peters, Jan},
file = {:home/didier/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kober, Peters - 2008 - Policy search for motor primitives in robotics.pdf:pdf},
journal = {NIPS},
keywords = {EM-based RL,PoWER},
mendeley-tags = {EM-based RL,PoWER},
pages = {1--8},
title = {{Policy search for motor primitives in robotics}},
year = {2008}
}
